"""
ML Response Schemas for AI Analysis Endpoint
Provides strict type validation for ML model outputs and AI analysis responses.

Prevents Map<String, dynamic> vs List<dynamic> runtime errors by enforcing
fixed schema structure with Pydantic validation.

Author: Backend AI Systems Team
"""

from pydantic import BaseModel, Field, field_validator
from typing import Dict, Union, List, Optional, Any
from datetime import datetime
from enum import Enum


class MLScoreBox(BaseModel):
    """
    Container for ML model predictions with metadata.

    All ML outputs MUST be wrapped in this structure to ensure:
    - Numeric predictions are always float type
    - Confidence scores are present
    - Model version is tracked for debugging
    """
    score: float = Field(..., ge=0.0, le=100.0, description="Prediction score (0.0 to 100.0)")
    confidence: float = Field(..., ge=0.0, le=1.0, description="Model confidence (0.0 to 1.0)")
    model_version: str = Field(..., description="Model version identifier (e.g., 'v1.2')")

    @field_validator('score')
    @classmethod
    def validate_score_range(cls, v: float) -> float:
        """Ensure score is within valid range (0-100)."""
        if not 0.0 <= v <= 100.0:
            raise ValueError(f"Score must be between 0.0 and 100.0, got {v}")
        return v

    @field_validator('confidence')
    @classmethod
    def validate_confidence_range(cls, v: float) -> float:
        """Ensure confidence is within valid range (0-1)."""
        if not 0.0 <= v <= 1.0:
            raise ValueError(f"Confidence must be between 0.0 and 1.0, got {v}")
        return v


class AIAnalysisSection(BaseModel):
    """
    AI-generated textual analysis output.

    Contains human-readable insights generated by AI layer.
    """
    summary: str = Field(..., min_length=1, description="Brief summary of analysis")
    detailed_insights: List[str] = Field(default_factory=list, description="Detailed insight points")
    recommendations: List[str] = Field(default_factory=list, description="Actionable recommendations")

    @field_validator('summary')
    @classmethod
    def validate_summary(cls, v: str) -> str:
        """Ensure summary is not empty."""
        if not v or not v.strip():
            raise ValueError("Summary cannot be empty")
        return v.strip()


class AnalysisMetadata(BaseModel):
    """
    Metadata for tracking performance and debugging.
    """
    calculation_timestamp: datetime = Field(..., description="When analysis was performed")
    ml_inference_time_ms: Optional[float] = Field(None, ge=0, description="ML inference time in milliseconds (None if not measured)")
    astro_calc_time_ms: float = Field(..., ge=0, description="Astrology calculation time in milliseconds")
    total_time_ms: float = Field(..., ge=0, description="Total processing time in milliseconds")
    llm_input_tokens: Optional[int] = Field(None, ge=0, description="LLM input tokens used (None if not measured)")
    llm_output_tokens: Optional[int] = Field(None, ge=0, description="LLM output tokens used (None if not measured)")
    llm_cost_usd: Optional[float] = Field(None, ge=0, description="Cost of LLM API call in USD")
    llm_request_duration_ms: Optional[float] = Field(None, ge=0, description="LLM API request duration in milliseconds")
    llm_cache_hit: Optional[bool] = Field(None, description="Whether LLM result was from cache")
    llm_model: Optional[str] = Field(None, description="LLM model used (e.g., claude-3-5-sonnet)")
    llm_fallback: Optional[bool] = Field(None, description="Whether fallback rule-based analysis was used")

    @field_validator('calculation_timestamp', mode='before')
    @classmethod
    def parse_timestamp(cls, v):
        """Parse timestamp if string is provided."""
        if isinstance(v, str):
            return datetime.fromisoformat(v.replace('Z', '+00:00'))
        return v


class AIAnalysisData(BaseModel):
    """
    Complete analysis data payload.

    CRITICAL: This structure is FIXED to prevent runtime type errors.
    - ml_scores MUST be Dict[str, MLScoreBox]
    - astrology_scores MUST be Dict[str, Union[int, float]]
    - NEVER use Union[List, Dict] or Any types
    """
    ml_scores: Dict[str, MLScoreBox] = Field(
        ...,
        description="ML model predictions, keyed by prediction type"
    )
    partner_ml_scores: Optional[Dict[str, MLScoreBox]] = Field(
        None,
        description="Partner's ML predictions (for compatibility analysis)"
    )
    astrology_scores: Dict[str, Union[int, float]] = Field(
        ...,
        description="Deterministic astrology scores"
    )
    ai_analysis: AIAnalysisSection = Field(
        ...,
        description="AI-generated textual analysis"
    )
    kundali_data: Optional[Dict[str, Any]] = Field(
        None,
        description="Complete kundali calculation data for LLM analysis"
    )
    metadata: AnalysisMetadata = Field(
        ...,
        description="Performance and debug metadata"
    )

    @field_validator('ml_scores')
    @classmethod
    def validate_ml_scores(cls, v: Dict[str, MLScoreBox]) -> Dict[str, MLScoreBox]:
        """Ensure ml_scores is a dict with MLScoreBox values."""
        if not isinstance(v, dict):
            raise ValueError(f"ml_scores must be dict, got {type(v).__name__}")

        if not v:
            raise ValueError("ml_scores cannot be empty")

        for key, val in v.items():
            if not isinstance(key, str):
                raise ValueError(f"ml_scores keys must be strings, got {type(key).__name__}")
            if not isinstance(val, MLScoreBox):
                raise ValueError(f"ml_scores['{key}'] must be MLScoreBox, got {type(val).__name__}")

        return v

    @field_validator('astrology_scores')
    @classmethod
    def validate_astrology_scores(cls, v: Dict[str, Union[int, float]]) -> Dict[str, Union[int, float]]:
        """Ensure astrology_scores is a dict with numeric values."""
        if not isinstance(v, dict):
            raise ValueError(f"astrology_scores must be dict, got {type(v).__name__}")

        if not v:
            raise ValueError("astrology_scores cannot be empty")

        for key, val in v.items():
            if not isinstance(key, str):
                raise ValueError(f"astrology_scores keys must be strings, got {type(key).__name__}")
            # Strict type checking: reject string numbers
            if isinstance(val, bool) or not isinstance(val, (int, float)):
                raise ValueError(f"astrology_scores['{key}'] must be int or float, got {type(val).__name__}")

        return v


class ResponseStatus(str, Enum):
    """Response status enumeration."""
    SUCCESS = "success"
    ERROR = "error"
    PARTIAL = "partial"


class AIAnalysisResponse(BaseModel):
    """
    Top-level response wrapper for /api/ai-analysis endpoint.

    Enforces consistent response structure across all AI analysis operations.
    """
    status: ResponseStatus = Field(..., description="Response status")
    success: bool = Field(..., description="Whether request was successful")
    data: AIAnalysisData = Field(..., description="Analysis data payload")
    timestamp: datetime = Field(default_factory=datetime.utcnow, description="Response timestamp")
    error_message: Union[str, None] = Field(None, description="Error message if failed")

    @field_validator('data')
    @classmethod
    def validate_data(cls, v: AIAnalysisData, info) -> AIAnalysisData:
        """Cross-validate data with success status."""
        values = info.data
        if values.get('success') and not v:
            raise ValueError("Success response must include data")
        return v

    model_config = {
        'json_schema_extra': {
            'example': {
                'status': 'success',
                'success': True,
                'data': {
                    'ml_scores': {
                        'wealth': {
                            'score': 0.75,
                            'confidence': 0.92,
                            'model_version': 'v1.2'
                        },
                        'career': {
                            'score': 0.68,
                            'confidence': 0.88,
                            'model_version': 'v1.2'
                        }
                    },
                    'astrology_scores': {
                        'guna_milan': 24,
                        'tara': 3,
                        'yoni': 4
                    },
                    'ai_analysis': {
                        'summary': 'High compatibility with strong career alignment',
                        'detailed_insights': [
                            'Excellent wealth prospects',
                            'Career paths align well'
                        ],
                        'recommendations': [
                            'Focus on joint financial planning',
                            'Support each other\'s career goals'
                        ]
                    },
                    'metadata': {
                        'calculation_timestamp': '2025-12-08T10:30:00Z',
                        'ml_inference_time_ms': 45.2,
                        'astro_calc_time_ms': 120.5,
                        'total_time_ms': 165.7
                    }
                },
                'timestamp': '2025-12-08T10:30:01Z',
                'error_message': None
            }
        }
    }


class AIAnalysisErrorResponse(BaseModel):
    """
    Error response for failed AI analysis requests.
    """
    status: ResponseStatus = Field(default=ResponseStatus.ERROR, description="Error status")
    success: bool = Field(default=False, description="Always false for errors")
    error_message: str = Field(..., description="Error description")
    error_code: str = Field(..., description="Machine-readable error code")
    timestamp: datetime = Field(default_factory=datetime.utcnow, description="Error timestamp")
    details: Union[Dict, None] = Field(None, description="Additional error details")
    data: Optional[Dict] = Field(None, description="No data in error responses")
